### [Titanic Survivors dataset from Kaggle](https://www.kaggle.com/c/titanic)  
description: Start here! Predict survival on the Titanic and get familiar with ML basics

1 data cleaning, which includes imputation(substitution of some value for missing data)  
2 feature engineering, this is quite important as good features can have amazing results even with a simple model such as Logistic Regression.  
3 L1 Regularized logistic regression. I use L1 regularization as it can select features. However, in this problem, you can easily select few variables that you think they are important. For example, you probably want to drop Name variable as it is almost unique to every person.  
4 Furthermore, you can experiment other low variance models for the sake of prediction, such as Random forests, bagging, and boosting.

