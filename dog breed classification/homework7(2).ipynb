{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework7(2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zvgqckwuNqjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Homework 7 - Berkeley STAT 157\n",
        "\n",
        "**Your name: XX, SID YY, teammates A,B,C** (Please add your name, SID and teammates to ease Ryan and Rachel to grade.)\n",
        "\n",
        "**Please submit your homework through [gradescope](http://gradescope.com/)**\n",
        "\n",
        "Handout 4/2/2019, due 4/9/2019 by 4pm.\n",
        "\n",
        "This homework deals with fine-tuning for computer vision. In this task, we attempt to identify 120 different breeds of dogs. The data set used in this competition is actually a subset of the ImageNet data set. Different from the images in the CIFAR-10 data set used in the previous homework, the images in the ImageNet data set are higher and wider and their dimensions are inconsistent. Again, you need to use GPU.\n",
        "\n",
        "The dataset is available at [Kaggle](https://www.kaggle.com/c/dog-breed-identification). The rule is similar to homework 6: \n",
        "\n",
        "- work as a team\n",
        "- submit your results into Kaggle\n",
        "- take a screen shot of your best score and insert it below\n",
        "- the top 3 teams/individuals will be awarded with 500 dollar AWS credits\n",
        "\n",
        "First, import the packages or modules required for the competition."
      ]
    },
    {
      "metadata": {
        "id": "5R2QldIPF58c",
        "colab_type": "code",
        "outputId": "df81b992-5a77-4ddf-899b-95b5dbc736ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1488
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install d2l mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting d2l\n",
            "  Downloading https://files.pythonhosted.org/packages/40/2b/618811a6331dc0cbb5d9731959f0c2b1b63bc1297c24401a3d7076e05624/d2l-0.8.7.tar.gz\n",
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/36/40b6d201b46495513f7a7fa25fe8b7d85b3602a22efba119e8146d5f1601/mxnet_cu100-1.4.0.post0-py2.py3-none-manylinux1_x86_64.whl (487.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 487.9MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l) (1.14.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l) (3.0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l) (1.0.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Collecting requests>=2.20.0 (from mxnet-cu100)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (2.5.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (4.4.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.4.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (4.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (7.4.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (6.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.2.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.22)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->d2l) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->d2l) (40.9.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (5.2.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (2.1.3)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (4.3.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (4.4.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (3.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (2.10)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (4.4.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (4.5.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l) (3.4.2)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->d2l)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K    100% |████████████████████████████████| 337kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (0.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->d2l) (17.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter->d2l) (4.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->jupyter->d2l) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->d2l) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->d2l) (0.6.0)\n",
            "Building wheels for collected packages: d2l\n",
            "  Building wheel for d2l (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c7/87/29/22170afbd70e10df77be0339d4e5863f452faa4a2f37ed979f\n",
            "Successfully built d2l\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: d2l, graphviz, requests, mxnet-cu100, prompt-toolkit\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Found existing installation: requests 2.18.4\n",
            "    Uninstalling requests-2.18.4:\n",
            "      Successfully uninstalled requests-2.18.4\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "Successfully installed d2l-0.8.7 graphviz-0.8.4 mxnet-cu100-1.4.0.post0 prompt-toolkit-2.0.9 requests-2.21.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f9XazfS3NqjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import d2l\n",
        "import math\n",
        "from mxnet import autograd, gluon, init, nd\n",
        "from mxnet.gluon import model_zoo, nn\n",
        "from mxnet.gluon import data as gdata, loss as gloss, utils as gutils\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import zipfile\n",
        "import mxnet as mx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSczco1VohYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r kaggle_dog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvxlQDp1IBLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir kaggle_dog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fi38Z1i2Hzbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp ../gdrive/My\\ Drive/labels.csv.zip ./kaggle_dog\n",
        "!cp ../gdrive/My\\ Drive/test.zip ./kaggle_dog\n",
        "!cp ../gdrive/My\\ Drive/train.zip ./kaggle_dog\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWbHjj68HaE3",
        "colab_type": "code",
        "outputId": "27995cc6-08c6-4d85-fd64-27aba1a496e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# !cp ../gdrive/My\\ Drive/stanford_lables.csv ./kaggle_dog\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '../gdrive/My Drive/stanford_lables.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C7_ihqplHalK",
        "colab_type": "code",
        "outputId": "07106be9-c8e0-43ff-a5f3-8469656e62fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_VVub9KjseFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir standford"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrcoriACG1UO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp ../gdrive/My\\ Drive/Images.zip ./standford\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipa-zcUGNqjL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Obtain and Organize the Data Sets\n",
        "\n",
        "The competition data is divided into a training set and testing set. The training set contains 10,222 images and the testing set contains 10,357 images. The images in both sets are in JPEG format. These images contain three RGB channels (color) and they have different heights and widths. There are 120 breeds of dogs in the training set, including Labradors, Poodles, Dachshunds, Samoyeds, Huskies, Chihuahuas, and Yorkshire Terriers.\n",
        "\n",
        "### Download the Data Set\n",
        "\n",
        "After logging in to Kaggle, we can click on the \"Data\" tab on the dog breed identification competition webpage shown in Figure 9.17 and download the training data set \"train.zip\", the testing data set \"test.zip\", and the training data set labels \"label.csv.zip\". After downloading the files, place them in the three paths below:\n",
        "\n",
        "* kaggle_dog/train.zip\n",
        "* kaggle_dog/test.zip\n",
        "* kaggle_dog/labels.csv.zip\n",
        "\n",
        "\n",
        "To make it easier to get started, we provide a small-scale sample of the data set mentioned above, \"train_valid_test_tiny.zip\". If you are going to use the full data set for the Kaggle competition, you will also need to change the `demo` variable below to `False`."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "aZSQByvVNqjM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you use the full data set downloaded for the Kaggle competition, \n",
        "# change the variable below to False.\n",
        "demo = False\n",
        "data_dir = './kaggle_dog'\n",
        "if demo:\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.mkdir(data_dir)\n",
        "    gutils.download('https://github.com/d2l-ai/d2l-en/raw/master/data/kaggle_dog/train_valid_test_tiny.zip', \n",
        "                    data_dir)\n",
        "    zipfiles = ['train_valid_test_tiny.zip']\n",
        "else:\n",
        "    zipfiles = ['train.zip', 'test.zip', 'labels.csv.zip']\n",
        "#     zipfiles = ['Images.zip']\n",
        "for f in zipfiles:\n",
        "    with zipfile.ZipFile(data_dir + '/' + f, 'r') as z:\n",
        "        z.extractall(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVt5gpN-slH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you use the full data set downloaded for the Kaggle competition, \n",
        "# change the variable below to False.\n",
        "demo = False\n",
        "data_dir = './standford'\n",
        "if demo:\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.mkdir(data_dir)\n",
        "    gutils.download('https://github.com/d2l-ai/d2l-en/raw/master/data/kaggle_dog/train_valid_test_tiny.zip', \n",
        "                    data_dir)\n",
        "    zipfiles = ['train_valid_test_tiny.zip']\n",
        "else:\n",
        "#     zipfiles = ['train.zip', 'test.zip', 'labels.csv.zip']\n",
        "    zipfiles = ['Images.zip']\n",
        "for f in zipfiles:\n",
        "    with zipfile.ZipFile(data_dir + '/' + f, 'r') as z:\n",
        "        z.extractall(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWqoMZc-NqjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
        "    # The number of examples of the least represented breed in the training set.\n",
        "    min_n_train_per_label = (\n",
        "        collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
        "    # The number of examples of each breed in the validation set.\n",
        "    n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
        "    label_count = {}\n",
        "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
        "        idx = train_file.split('.')[0]\n",
        "        label = idx_label[idx]\n",
        "        d2l.mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
        "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
        "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
        "            label_count[label] = label_count.get(label, 0) + 1\n",
        "        else:\n",
        "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                        os.path.join(data_dir, input_dir, 'train', label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kh9d-o2wNqjS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `reorg_dog_data` function below is used to read the training data labels, segment the validation set, and organize the training set."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "2"
        },
        "id": "7Hivu72HNqjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
        "                   valid_ratio):\n",
        "    # Read the training data labels.\n",
        "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
        "        # Skip the file header line (column name).\n",
        "        lines = f.readlines()[1:]\n",
        "        tokens = [l.rstrip().split(',') for l in lines]\n",
        "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
        "    reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
        "    # Organize the training set.\n",
        "    d2l.mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
        "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
        "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
        "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CpwasAGaNqjV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because we are using a small data set, we set the batch size to 1. During actual training and testing, we would use the entire Kaggle Competition data set and call the `reorg_dog_data` function to organize the data set. Likewise, we would need to set the `batch_size` to a larger integer, such as 128."
      ]
    },
    {
      "metadata": {
        "id": "E9vhSj2ro-bh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "demo = False\n",
        "if demo:\n",
        "    # Note: Here, we use a small data set and the batch size should be set\n",
        "    # smaller. When using the complete data set for the Kaggle competition, \n",
        "    # we can set the batch size to a larger integer.\n",
        "    input_dir, batch_size = 'train_valid_test_tiny', 1\n",
        "else:\n",
        "    label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
        "    input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
        "    reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
        "                   valid_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvkqhOItNqjZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation\n",
        "\n",
        "The size of the images in this section are larger than the images in the previous section. Here are some more image augmentation operations that might be useful."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "id": "gD4zKq8gNqja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_train = gdata.vision.transforms.Compose([\n",
        "    # Randomly crop the image to obtain an image with an area of 0.08 to 1 \n",
        "    # of the original area and height to width ratio between 3/4 and 4/3.\n",
        "    # Then, scale the image to create a new image with a height and width \n",
        "    # of 224 pixels each.\n",
        "    gdata.vision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
        "                                              ratio=(3.0/4.0, 4.0/3.0)),\n",
        "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
        "    # Randomly change the brightness, contrast, and saturation.\n",
        "    gdata.vision.transforms.RandomColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                              saturation=0.4),\n",
        "    # Add random noise.\n",
        "    gdata.vision.transforms.RandomLighting(0.1),\n",
        "    gdata.vision.transforms.ToTensor(),\n",
        "    # Standardize each channel of the image.\n",
        "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                      [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mjb39F7Nqje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "During testing, we only use definite image preprocessing operations."
      ]
    },
    {
      "metadata": {
        "id": "qnh3_UAbNqjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_test = gdata.vision.transforms.Compose([\n",
        "    gdata.vision.transforms.Resize(256),\n",
        "    # Crop a square of 224 by 224 from the center of the image.\n",
        "    gdata.vision.transforms.CenterCrop(224),\n",
        "    gdata.vision.transforms.ToTensor(),\n",
        "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                      [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRZwkXFCNqjj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read the Data Set\n",
        "\n",
        "As in the previous section, we can create an `ImageFolderDataset` instance to read the data set containing the original image files."
      ]
    },
    {
      "metadata": {
        "id": "6fp8AFmkfU9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#demo\n",
        "train_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
        "valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
        "train_valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
        "train_iter = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
        "                              batch_size, shuffle=True, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "SDfhreBjNqjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_ds = gdata.vision.ImageFolderDataset(\n",
        "#     os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
        "# valid_ds = gdata.vision.ImageFolderDataset(\n",
        "#     os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
        "# train_valid_ds = gdata.vision.ImageFolderDataset(\n",
        "#     os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
        "test_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join('./kaggle_dog', input_dir, 'test'), flag=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejCl470WNqjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we create a `DataLoader` instance, just like in the previous section."
      ]
    },
    {
      "metadata": {
        "id": "aQbS3UGaNqjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join('./standford', 'Images'), flag=1)\n",
        "\n",
        "train_iter = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
        "                              batch_size, shuffle=True, last_batch='keep')\n",
        "# valid_iter = gdata.DataLoader(valid_ds.transform_first(transform_test),\n",
        "#                               batch_size, shuffle=True, last_batch='keep')\n",
        "# train_valid_iter = gdata.DataLoader(train_valid_ds.transform_first(\n",
        "#     transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "# test_iter = gdata.DataLoader(test_ds.transform_first(transform_test),\n",
        "#                              batch_size, shuffle=False, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdSARbb6pOJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_iter = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
        "#                               batch_size, shuffle=True, last_batch='keep')\n",
        "# valid_iter = gdata.DataLoader(valid_ds.transform_first(transform_test),\n",
        "#                               batch_size, shuffle=True, last_batch='keep')\n",
        "# train_valid_iter = gdata.DataLoader(train_valid_ds.transform_first(\n",
        "#     transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "test_iter = gdata.DataLoader(test_ds.transform_first(transform_test),\n",
        "                             batch_size, shuffle=False, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yMAgUiPtNqjr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the Model\n",
        "\n",
        "The data set for this competition is a subset of the ImageNet data set. Therefore, we can use the approach discussed in the [\"Fine Tuning\"](fine-tuning.md) section to select a model pre-trained on the entire ImageNet data set and use it to extract image features to be input in the custom small-scale output network. Gluon provides a wide range of pre-trained models. Here, we will use the pre-trained ResNet-34 model. Because the competition data set is a subset of the pre-training data set, we simply reuse the input of the pre-trained model's output layer, i.e. the extracted features. Then, we can replace the original output layer with a small custom output network that can be trained, such as two fully connected layers in a series. Different from the experiment in the [\"Fine Tuning\"](fine-tuning.md) section, here, we do not retrain the pre-trained model used for feature extraction. This reduces the training time and the memory required to store model parameter gradients.\n",
        "\n",
        "You must note that, during image augmentation, we use the mean values and standard deviations of the three RGB channels for the entire ImageNet data set for normalization. This is consistent with the normalization of the pre-trained model."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "-mw7MOKuNqjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_net(ctx):\n",
        "    finetune_net = model_zoo.vision.resnet152_v2(pretrained=True)\n",
        "#     finetune_net = model_zoo.vision.resnet34_v2(pretrained=True)\n",
        "    # Define a new output network.\n",
        "    finetune_net.output_new = nn.HybridSequential(prefix='')\n",
        "    finetune_net.output_new.add(nn.Dense(256, activation='relu'))\n",
        "    # There are 120 output categories.\n",
        "    finetune_net.output_new.add(nn.Dropout(0.5))\n",
        "    finetune_net.output_new.add(nn.Dense(120))\n",
        "    # Initialize the output network.\n",
        "    finetune_net.output_new.initialize(init.Xavier(), ctx=ctx)\n",
        "    # Distribute the model parameters to the CPUs or GPUs used for computation.\n",
        "    finetune_net.collect_params().reset_ctx(ctx)\n",
        "    return finetune_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKWZcIRsNqju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When calculating the loss, we first use the member variable `features` to obtain the input of the pre-trained model's output layer, i.e. the extracted feature. Then, we use this feature as the input for our small custom output network and compute the output."
      ]
    },
    {
      "metadata": {
        "id": "YgtnmcukNqjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = gloss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "def evaluate_loss(data_iter, net, ctx):\n",
        "    l_sum, n = 0.0, 0\n",
        "    for X, y in data_iter:\n",
        "        y = y.as_in_context(ctx)\n",
        "        output_features = net.features(X.as_in_context(ctx))\n",
        "        outputs = net.output_new(output_features)\n",
        "        l_sum += loss(outputs, y).sum().asscalar()\n",
        "        n += y.size\n",
        "    return l_sum / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JuyMAsxxNqjx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the Training Functions\n",
        "\n",
        "We will select the model and tune hyper-parameters according to the model's performance on the validation set. The model training function `train` only trains the small custom output network."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "pNYakfw1Nqjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period,\n",
        "          lr_decay):\n",
        "    # Only train the small custom output network.\n",
        "    trainer = gluon.Trainer(net.output_new.collect_params(), 'sgd',\n",
        "                            {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, n, start = 0.0, 0, time.time()\n",
        "        acc_top1_val = mx.metric.Accuracy()\n",
        "        \n",
        "        for X, y in train_iter:\n",
        "            y = y.as_in_context(ctx)\n",
        "            output_features = net.features(X.as_in_context(ctx))\n",
        "            with autograd.record():\n",
        "                outputs = net.output_new(output_features)\n",
        "                l = loss(outputs, y).sum()\n",
        "                acc_top1_val.update(y, outputs)\n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "            train_l_sum += l.asscalar()\n",
        "            n += y.size\n",
        "        time_s = \"time %.2f sec\" % (time.time() - start)\n",
        "        if valid_iter is not None:\n",
        "            valid_loss = evaluate_loss(valid_iter, net, ctx)\n",
        "            epoch_s = (\"epoch %d, train loss %f, valid loss %f, \"\n",
        "                       % (epoch + 1, train_l_sum / n, valid_loss))\n",
        "        else:\n",
        "            epoch_s = (\"epoch %d, train loss %f, \"\n",
        "                       % (epoch + 1, train_l_sum / n))\n",
        "        acc = acc_top1_val.get()[1]\n",
        "        if train_l_sum / n <=0.6:\n",
        "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
        "        print(epoch_s + time_s + ', lr ' + str(trainer.learning_rate)+\" acc: \"+str(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5f5zoQfyNqj0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and Validate the Model\n",
        "\n",
        "Now, we can train and validate the model. The following hyper-parameters can be tuned. For example, we can increase the number of epochs. Because `lr_period` and `lr_decay` are set to 10 and 0.1 respectively, the learning rate of the optimization algorithm will be multiplied by 0.1 after every 10 epochs."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "9"
        },
        "id": "ggGWkOm3Nqj2",
        "colab_type": "code",
        "outputId": "eb472c8b-c05f-474e-972a-6b41f49b78c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "ctx, num_epochs, lr, wd = d2l.try_gpu(), 20, 0.01, 1e-4\n",
        "lr_period, lr_decay, net = 20, 0.1, get_net(ctx)\n",
        "net.hybridize()\n",
        "# train(net, train_iter, None, num_epochs, lr, wd, ctx, lr_period,\n",
        "#       lr_decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet152_v2-f2695542.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet152_v2-f2695542.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0GIYf3TWNqj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classify the Testing Set and Submit Results on Kaggle\n",
        "\n",
        "After obtaining a satisfactory model design and hyper-parameters, we use all training data sets (including validation sets) to retrain the model and then classify the testing set. Note that predictions are made by the output network we just trained."
      ]
    },
    {
      "metadata": {
        "id": "CykbYIZLnVtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.save_parameters(\"net.params\")\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'net.params'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdW9muSR4Ouv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = get_net(ctx)\n",
        "# net.save_parameters(\"net.params\")\n",
        "# net.load_parameters(\"net.params\", ctx)\n",
        "net.load_parameters(\"resnet152v2.params\", ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "C05nVrmeNqkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# net = get_net(ctx)\n",
        "# net.hybridize()\n",
        "# train(net, train_valid_iter, None, num_epochs, lr, wd, ctx, lr_period,\n",
        "#       lr_decay)\n",
        "\n",
        "preds = []\n",
        "for data, label in test_iter:\n",
        "    output_features = net.features(data.as_in_context(ctx))\n",
        "    output = nd.softmax(net.output_new(output_features))\n",
        "    preds.extend(output.asnumpy())\n",
        "ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
        "with open('submission.csv', 'w') as f:\n",
        "    f.write('id,' + ','.join(train_valid_ds.synsets) + '\\n')\n",
        "    for i, output in zip(ids, preds):\n",
        "        f.write(i.split('.')[0] + ',' + ','.join(\n",
        "            [str(num) for num in output]) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0UI0oYeTq-Fn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0TcNpLG_NqkK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After executing the above code, we will generate a \"submission.csv\" file. The format of this file is consistent with the Kaggle competition requirements. \n",
        "\n",
        "## Hints to Improve Your Results\n",
        "\n",
        "* You should download the whole data set from Kaggle and switch to `demo=False`. \n",
        "* Try to increase the `batch_size` (batch size) and `num_epochs` (number of epochs).\n",
        "* Try a deeper pre-trained model, you may find models from [gluoncv](https://gluon-cv.mxnet.io/model_zoo/classification.html)."
      ]
    },
    {
      "metadata": {
        "id": "3MUpmNMVnpwi",
        "colab_type": "code",
        "outputId": "e39bf882-a467-4439-fcdf-b60d68c48c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1XTY8hUqDIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a JSON file containing user-specific metadata. \n",
        "# This step is required if you want to access the Kaggle API.  \n",
        "# For more info see: https://github.com/Kaggle/kaggle-api#api-credentials\n",
        "USER_ID = 'caojilin' # REPLACE WITH YOUR OWN USER NAME\n",
        "USER_SECRET = \"95413dff633e902356ea9fc5b87e682d\" # REPLACE WITH YOUR OWN PRIVATE API TOKEN\n",
        "import os, json, nbformat, pandas as pd\n",
        "KAGGLE_CONFIG_DIR = os.path.join(os.path.expandvars('$HOME'), '.kaggle')\n",
        "os.makedirs(KAGGLE_CONFIG_DIR, exist_ok = True)\n",
        "with open(os.path.join(KAGGLE_CONFIG_DIR, 'kaggle.json'), 'w') as f:\n",
        "    json.dump({'username': USER_ID, 'key': USER_SECRET}, f)\n",
        "!chmod 600 {KAGGLE_CONFIG_DIR}/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-dbwb2yoC1K",
        "colab_type": "code",
        "outputId": "83fb3a48-590d-42ba-a397-7437b378b015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c dog-breed-identification -f submission.csv -m \"through kaggle api submittion\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 16.4M/16.4M [00:05<00:00, 3.33MB/s]\n",
            "Successfully submitted to Dog Breed Identification"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AUqs4pBHKjVJ",
        "colab_type": "code",
        "outputId": "a7539a61-04f3-4882-a18d-9ede76513a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c dog-breed-identification -f p3.csv -m \"through kaggle api submittion\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 16.4M/16.4M [00:05<00:00, 3.18MB/s]\n",
            "Successfully submitted to Dog Breed Identification"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lmmwMO1sqegg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mxnet import autograd\n",
        "from mxnet import gluon\n",
        "from mxnet import image\n",
        "from mxnet import init\n",
        "from mxnet import nd\n",
        "from mxnet.gluon.data import vision\n",
        "import numpy as np\n",
        "\n",
        "label_file = 'labels.csv'\n",
        "train_dir = 'train'\n",
        "test_dir = 'test'\n",
        "input_dir = 'train_valid_test'\n",
        "batch_size = 128\n",
        "valid_ratio = 0.1\n",
        "\n",
        "def transform_train(data, label):\n",
        "    im = image.imresize(data.astype('float32') / 255, 363, 363)\n",
        "    #im = image.imresize(data.astype('float32') / 255, 400, 400)\n",
        "    auglist = image.CreateAugmenter(data_shape=(3, 363, 363), resize=0, \n",
        "                        rand_crop=False, rand_resize=False, rand_mirror=True,\n",
        "                        mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]), \n",
        "                        brightness=0, contrast=0, \n",
        "                        saturation=0, hue=0, \n",
        "                        pca_noise=0, rand_gray=0, inter_method=2)\n",
        "    for aug in auglist:\n",
        "        im = aug(im)\n",
        "    \n",
        "    # transform height x weight x channels to channels x height x weight\n",
        "    im = nd.transpose(im, (2,0,1))\n",
        "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
        "\n",
        "def transform_test(data, label):\n",
        "    im = image.imresize(data.astype('float32') / 255, 363, 363)\n",
        "    auglist = image.CreateAugmenter(data_shape=(3, 363, 363),\n",
        "                        mean=np.array([0.485, 0.456, 0.406]),\n",
        "                        std=np.array([0.229, 0.224, 0.225]))\n",
        "    for aug in auglist:\n",
        "        im = aug(im)\n",
        "    im = nd.transpose(im, (2,0,1))\n",
        "    return (im, nd.array([label]).asscalar().astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TfrA67PQZ3Zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_str = data_dir + '/' + input_dir + '/'\n",
        "\n",
        "train_ds = vision.ImageFolderDataset(input_str + 'train', flag=1,\n",
        "                                     transform=transform_train)\n",
        "valid_ds = vision.ImageFolderDataset(input_str + 'valid', flag=1,\n",
        "                                     transform=transform_test)\n",
        "train_valid_ds = vision.ImageFolderDataset(input_str + 'train_valid',\n",
        "                                           flag=1, transform=transform_train)\n",
        "test_ds = vision.ImageFolderDataset(input_str + 'test', flag=1,\n",
        "                                     transform=transform_test)\n",
        "\n",
        "loader = gluon.data.DataLoader\n",
        "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
        "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
        "train_valid_data = loader(train_valid_ds, batch_size, shuffle=True,\n",
        "                          last_batch='keep')\n",
        "test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6pIArPkYDXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#herererrererere\n",
        "train_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
        "valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
        "train_valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
        "test_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'test'), flag=1)\n",
        "\n",
        "train_data = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
        "                              batch_size, shuffle=True, last_batch='keep')\n",
        "valid_data = gdata.DataLoader(valid_ds.transform_first(transform_test),\n",
        "                              batch_size, shuffle=True, last_batch='keep')\n",
        "train_valid_data = gdata.DataLoader(train_valid_ds.transform_first(\n",
        "    transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "test_data = gdata.DataLoader(test_ds.transform_first(transform_test),\n",
        "                             batch_size, shuffle=False, last_batch='keep')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g52iVEB-GAM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mxnet import gluon\n",
        "from mxnet import init\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "def get_features(ctx):\n",
        "    inception = model_zoo.vision.inception_v3(pretrained=True,ctx=ctx)\n",
        "    return inception.features\n",
        "\n",
        "\n",
        "def get_output(ctx,ParamsName=None):\n",
        "    net = nn.HybridSequential()\n",
        "    with net.name_scope():\n",
        "        net.add(nn.Dropout(.2))\n",
        "        net.add(nn.Dense(256, activation=\"relu\"))\n",
        "        net.add(nn.Dropout(.6))\n",
        "        net.add(nn.Dense(120))\n",
        "    if ParamsName is not None:\n",
        "        #net.collect_params().load(ParamsName,ctx)\n",
        "        net.load_parameters(ParamsName,ctx)\n",
        "    else:\n",
        "        net.initialize(init = init.Xavier(),ctx=ctx)\n",
        "    return net\n",
        "\n",
        "def get_net(ParamsName,ctx):\n",
        "    output = get_output(ctx,ParamsName)\n",
        "    features = get_features(ctx)\n",
        "    net = nn.HybridSequential()\n",
        "    with net.name_scope():\n",
        "        net.add(features)\n",
        "        net.add(output)\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UeCvRHe8GAf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mxnet as mx\n",
        "net2=get_features(mx.gpu())\n",
        "# print(net2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xwQg0L_GAlr",
        "colab_type": "code",
        "outputId": "b6562e69-4106-4f17-999f-811adf1b9d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6262
        }
      },
      "cell_type": "code",
      "source": [
        "from mxnet import nd\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "net = get_features(mx.gpu())\n",
        "net.hybridize()\n",
        "\n",
        "def SaveNd(data,net,name):\n",
        "    x =[]\n",
        "    y =[]\n",
        "    print('extract features %s' % name)\n",
        "    for fear,label in tqdm(data):\n",
        "        x.append(net(fear.as_in_context(mx.gpu())).as_in_context(mx.cpu()))\n",
        "        y.append(label)\n",
        "    x = nd.concat(*x,dim=0)\n",
        "    y = nd.concat(*y,dim=0)\n",
        "    print('save features %s' % name)\n",
        "    nd.save(name,[x,y])\n",
        "\n",
        "\n",
        "SaveNd(train_data,net,'train_inception_v3.nd')\n",
        "SaveNd(valid_data,net,'valid_inception_v3.nd')\n",
        "SaveNd(train_valid_data,net,'input_inception_v3.nd')\n",
        "# SaveNd(test_data,net,'test_resnet152_v1.nd')\n",
        "ids = ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
        "synsets = train_valid_ds.synsets\n",
        "f = open('ids_synsets','wb')\n",
        "pickle.dump([ids,synsets],f)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extract features train_inception_v3.nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|▏         | 1/75 [00:02<03:30,  2.85s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 2/75 [00:05<03:32,  2.91s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 3/75 [00:09<03:33,  2.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 4/75 [00:12<03:32,  3.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 5/75 [00:15<03:33,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 6/75 [00:18<03:30,  3.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 7/75 [00:21<03:28,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 8/75 [00:24<03:28,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 9/75 [00:27<03:27,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 10/75 [00:30<03:23,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 11/75 [00:34<03:19,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 12/75 [00:37<03:20,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 13/75 [00:40<03:16,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 14/75 [00:43<03:11,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 15/75 [00:46<03:09,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 16/75 [00:50<03:11,  3.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 17/75 [00:53<03:08,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 18/75 [00:56<03:06,  3.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 19/75 [01:00<03:01,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 20/75 [01:03<02:55,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 21/75 [01:06<02:52,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 22/75 [01:09<02:47,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 23/75 [01:12<02:41,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 24/75 [01:15<02:38,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 25/75 [01:18<02:35,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 26/75 [01:21<02:35,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 27/75 [01:25<02:32,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 28/75 [01:28<02:29,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 29/75 [01:31<02:24,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 30/75 [01:34<02:21,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 31/75 [01:37<02:17,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 32/75 [01:40<02:14,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 33/75 [01:43<02:12,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 34/75 [01:46<02:06,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 35/75 [01:49<02:03,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 36/75 [01:53<02:02,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 37/75 [01:56<02:01,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 38/75 [01:59<01:56,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 39/75 [02:02<01:52,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 40/75 [02:05<01:50,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 41/75 [02:08<01:46,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 42/75 [02:11<01:42,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 43/75 [02:15<01:39,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 44/75 [02:18<01:37,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 45/75 [02:21<01:34,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 46/75 [02:24<01:29,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 47/75 [02:27<01:27,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 48/75 [02:30<01:24,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 49/75 [02:33<01:21,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 50/75 [02:37<01:18,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 51/75 [02:40<01:15,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 52/75 [02:43<01:12,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 53/75 [02:46<01:09,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 54/75 [02:49<01:05,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 55/75 [02:52<01:02,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 56/75 [02:55<00:59,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 57/75 [02:58<00:56,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 58/75 [03:02<00:53,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 59/75 [03:05<00:50,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 60/75 [03:08<00:46,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 61/75 [03:11<00:43,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 62/75 [03:14<00:40,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 63/75 [03:17<00:36,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 64/75 [03:20<00:33,  3.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 65/75 [03:23<00:30,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 66/75 [03:26<00:28,  3.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 67/75 [03:30<00:25,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 68/75 [03:33<00:22,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 69/75 [03:36<00:19,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 70/75 [03:39<00:15,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 71/75 [03:42<00:12,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 72/75 [03:45<00:09,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 73/75 [03:48<00:06,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 74/75 [03:52<00:03,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 75/75 [03:52<00:00,  2.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "save features train_inception_v3.nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extract features valid_inception_v3.nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [00:01<00:09,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:04<00:08,  2.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:06<00:06,  2.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:09<00:04,  2.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:11<00:02,  2.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:13<00:00,  2.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "save features valid_inception_v3.nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extract features input_inception_v3.nd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|▏         | 1/80 [00:02<03:27,  2.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▎         | 2/80 [00:05<03:38,  2.81s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 3/80 [00:09<03:44,  2.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 4/80 [00:12<03:48,  3.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 5/80 [00:15<03:47,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 6/80 [00:18<03:50,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 7/80 [00:21<03:47,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 8/80 [00:24<03:41,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 9/80 [00:27<03:38,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▎        | 10/80 [00:31<03:39,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 11/80 [00:34<03:36,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 12/80 [00:37<03:34,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 13/80 [00:40<03:28,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 14/80 [00:43<03:27,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 15/80 [00:46<03:23,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 16/80 [00:49<03:19,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 17/80 [00:53<03:21,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▎       | 18/80 [00:56<03:26,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 19/80 [01:00<03:27,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 20/80 [01:03<03:20,  3.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 21/80 [01:06<03:12,  3.26s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 22/80 [01:09<03:05,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 23/80 [01:12<03:00,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 24/80 [01:15<02:54,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 25/80 [01:18<02:50,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▎      | 26/80 [01:22<02:47,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 27/80 [01:25<02:42,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 28/80 [01:27<02:36,  3.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 29/80 [01:31<02:36,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 30/80 [01:34<02:37,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 31/80 [01:37<02:36,  3.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 32/80 [01:40<02:31,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 33/80 [01:43<02:26,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▎     | 34/80 [01:46<02:22,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 35/80 [01:49<02:18,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 36/80 [01:53<02:15,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 37/80 [01:55<02:09,  3.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 38/80 [01:58<02:07,  3.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 39/80 [02:02<02:06,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 40/80 [02:05<02:02,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 41/80 [02:08<01:59,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▎    | 42/80 [02:11<01:57,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 43/80 [02:14<01:54,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 44/80 [02:17<01:51,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 45/80 [02:20<01:49,  3.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▊    | 46/80 [02:23<01:45,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 47/80 [02:26<01:42,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 48/80 [02:30<01:38,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 49/80 [02:33<01:36,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▎   | 50/80 [02:36<01:32,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 51/80 [02:39<01:28,  3.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 52/80 [02:42<01:25,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 53/80 [02:45<01:23,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 54/80 [02:48<01:21,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 55/80 [02:52<01:20,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 56/80 [02:55<01:18,  3.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 57/80 [02:58<01:14,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▎  | 58/80 [03:01<01:09,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 59/80 [03:04<01:05,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 60/80 [03:07<01:01,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▋  | 61/80 [03:10<00:57,  3.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 62/80 [03:13<00:54,  3.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 63/80 [03:16<00:52,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 64/80 [03:20<00:50,  3.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 65/80 [03:23<00:46,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▎ | 66/80 [03:26<00:43,  3.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 67/80 [03:29<00:40,  3.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 68/80 [03:32<00:36,  3.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 69/80 [03:35<00:33,  3.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 70/80 [03:38<00:30,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 71/80 [03:41<00:27,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 72/80 [03:44<00:24,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 73/80 [03:47<00:21,  3.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▎| 74/80 [03:50<00:18,  3.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 75/80 [03:53<00:15,  3.00s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 76/80 [03:56<00:11,  2.99s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 77/80 [03:59<00:09,  3.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 78/80 [04:02<00:06,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 79/80 [04:05<00:03,  3.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 80/80 [04:08<00:00,  2.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "save features input_inception_v3.nd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7DaO3nU7GTP2",
        "colab_type": "code",
        "outputId": "09ba83c2-2cc7-41a9-f93b-5481a362109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2772
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from mxnet import autograd\n",
        "from mxnet import gluon\n",
        "from mxnet import image\n",
        "from mxnet import init\n",
        "from mxnet import nd\n",
        "from mxnet.gluon.data import vision\n",
        "from mxnet.gluon import nn\n",
        "from mxnet import nd\n",
        "import pandas as pd\n",
        "import mxnet as mx\n",
        "import pickle\n",
        "\n",
        "train_nd = nd.load('train_inception_v3.nd')\n",
        "\n",
        "valid_nd = nd.load('valid_inception_v3.nd')\n",
        "\n",
        "input_nd = nd.load('input_inception_v3.nd')\n",
        "\n",
        "f = open('ids_synsets','rb')\n",
        "ids_synsets = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "num_epochs = 150\n",
        "batch_size = 128\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "lr_period = 100\n",
        "lr_decay = 0.1\n",
        "pngname='1'\n",
        "modelparams='1'\n",
        "\n",
        "train_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(train_nd[0],train_nd[1]), batch_size=batch_size,shuffle=True)\n",
        "valid_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(valid_nd[0],valid_nd[1]), batch_size=batch_size,shuffle=True)\n",
        "input_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(input_nd[0],input_nd[1]), batch_size=batch_size,shuffle=True)\n",
        "\n",
        "\n",
        "def get_loss(data, net, ctx):\n",
        "    loss = 0.0\n",
        "    for feas, label in data:\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = net(feas.as_in_context(ctx))\n",
        "        cross_entropy = softmax_cross_entropy(output, label)\n",
        "        loss += nd.mean(cross_entropy).asscalar()\n",
        "    return loss / len(data)\n",
        "\n",
        "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period, \n",
        "          lr_decay):\n",
        "    trainer = gluon.Trainer(\n",
        "        net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd})\n",
        "    #trainer = gluon.Trainer(\n",
        "     #   net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
        "      #                                'wd': wd})\n",
        "    train_loss = []\n",
        "    if valid_data is not None:\n",
        "        test_loss = []\n",
        "    \n",
        "    prev_time = datetime.datetime.now()\n",
        "    for epoch in range(num_epochs):\n",
        "        _loss = 0.\n",
        "        if epoch > 0 and epoch % lr_period == 0:\n",
        "           trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
        "        for data, label in train_data:\n",
        "            label = label.as_in_context(ctx)\n",
        "            with autograd.record():\n",
        "                output = net(data.as_in_context(ctx))\n",
        "                loss = softmax_cross_entropy(output, label)\n",
        "            loss.backward()\n",
        "            trainer.step(batch_size)\n",
        "            _loss += nd.mean(loss).asscalar()\n",
        "        cur_time = datetime.datetime.now()\n",
        "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
        "        m, s = divmod(remainder, 60)\n",
        "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
        "        __loss = _loss/len(train_data)\n",
        "        train_loss.append(__loss)\n",
        "        \n",
        "        if valid_data is not None:  \n",
        "            valid_loss = get_loss(valid_data, net, ctx)\n",
        "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
        "                         % (epoch,__loss , valid_loss))\n",
        "            test_loss.append(valid_loss)\n",
        "        else:\n",
        "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
        "                         % (epoch, __loss))\n",
        "            \n",
        "        prev_time = cur_time\n",
        "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
        "        \n",
        "\n",
        "    plt.plot(train_loss, 'r')\n",
        "    if valid_data is not None: \n",
        "        plt.plot(test_loss, 'g')\n",
        "    plt.legend(['Train_Loss', 'Test_Loss'], loc=2)\n",
        "\n",
        "\n",
        "    plt.savefig(pngname, dpi=1000)\n",
        "    #net.collect_params().save(modelparams)\n",
        "    savefilename = \"./inception_v3.params\"\n",
        "    net.save_parameters(savefilename)\n",
        "\n",
        "ctx = mx.gpu()\n",
        "net = get_output(ctx)\n",
        "net.hybridize()\n",
        "\n",
        "#train(net, input_data_d,None, num_epochs, learning_rate, weight_decay, \n",
        " #     ctx, lr_period, lr_decay)\n",
        "train(net, train_data_d,valid_data_d, num_epochs, learning_rate, weight_decay, \n",
        "      ctx, lr_period, lr_decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Train loss: 4.597775, Valid loss 4.101457, Time 00:00:00, lr 0.0001\n",
            "Epoch 1. Train loss: 3.824505, Valid loss 2.981406, Time 00:00:00, lr 0.0001\n",
            "Epoch 2. Train loss: 2.860231, Valid loss 1.957403, Time 00:00:00, lr 0.0001\n",
            "Epoch 3. Train loss: 2.109669, Valid loss 1.282627, Time 00:00:00, lr 0.0001\n",
            "Epoch 4. Train loss: 1.615409, Valid loss 0.903502, Time 00:00:00, lr 0.0001\n",
            "Epoch 5. Train loss: 1.287589, Valid loss 0.698177, Time 00:00:00, lr 0.0001\n",
            "Epoch 6. Train loss: 1.100800, Valid loss 0.568821, Time 00:00:00, lr 0.0001\n",
            "Epoch 7. Train loss: 0.949393, Valid loss 0.496424, Time 00:00:00, lr 0.0001\n",
            "Epoch 8. Train loss: 0.833068, Valid loss 0.443741, Time 00:00:00, lr 0.0001\n",
            "Epoch 9. Train loss: 0.777226, Valid loss 0.417439, Time 00:00:00, lr 0.0001\n",
            "Epoch 10. Train loss: 0.697814, Valid loss 0.382606, Time 00:00:00, lr 0.0001\n",
            "Epoch 11. Train loss: 0.654586, Valid loss 0.363719, Time 00:00:00, lr 0.0001\n",
            "Epoch 12. Train loss: 0.619057, Valid loss 0.353833, Time 00:00:00, lr 0.0001\n",
            "Epoch 13. Train loss: 0.589004, Valid loss 0.334335, Time 00:00:00, lr 0.0001\n",
            "Epoch 14. Train loss: 0.553377, Valid loss 0.329538, Time 00:00:00, lr 0.0001\n",
            "Epoch 15. Train loss: 0.543532, Valid loss 0.325034, Time 00:00:00, lr 0.0001\n",
            "Epoch 16. Train loss: 0.505737, Valid loss 0.306580, Time 00:00:00, lr 0.0001\n",
            "Epoch 17. Train loss: 0.493802, Valid loss 0.302124, Time 00:00:00, lr 0.0001\n",
            "Epoch 18. Train loss: 0.467941, Valid loss 0.286762, Time 00:00:00, lr 0.0001\n",
            "Epoch 19. Train loss: 0.455366, Valid loss 0.290420, Time 00:00:00, lr 0.0001\n",
            "Epoch 20. Train loss: 0.436646, Valid loss 0.281586, Time 00:00:00, lr 0.0001\n",
            "Epoch 21. Train loss: 0.427034, Valid loss 0.285841, Time 00:00:00, lr 0.0001\n",
            "Epoch 22. Train loss: 0.421051, Valid loss 0.275300, Time 00:00:00, lr 0.0001\n",
            "Epoch 23. Train loss: 0.409879, Valid loss 0.287792, Time 00:00:00, lr 0.0001\n",
            "Epoch 24. Train loss: 0.390727, Valid loss 0.277090, Time 00:00:00, lr 0.0001\n",
            "Epoch 25. Train loss: 0.386881, Valid loss 0.272466, Time 00:00:00, lr 0.0001\n",
            "Epoch 26. Train loss: 0.370625, Valid loss 0.271578, Time 00:00:00, lr 0.0001\n",
            "Epoch 27. Train loss: 0.365305, Valid loss 0.269531, Time 00:00:00, lr 0.0001\n",
            "Epoch 28. Train loss: 0.359419, Valid loss 0.284265, Time 00:00:00, lr 0.0001\n",
            "Epoch 29. Train loss: 0.347255, Valid loss 0.266467, Time 00:00:00, lr 0.0001\n",
            "Epoch 30. Train loss: 0.341377, Valid loss 0.267979, Time 00:00:00, lr 0.0001\n",
            "Epoch 31. Train loss: 0.337758, Valid loss 0.272910, Time 00:00:00, lr 0.0001\n",
            "Epoch 32. Train loss: 0.326046, Valid loss 0.261868, Time 00:00:00, lr 0.0001\n",
            "Epoch 33. Train loss: 0.318685, Valid loss 0.262676, Time 00:00:00, lr 0.0001\n",
            "Epoch 34. Train loss: 0.311012, Valid loss 0.260008, Time 00:00:00, lr 0.0001\n",
            "Epoch 35. Train loss: 0.317710, Valid loss 0.260068, Time 00:00:00, lr 0.0001\n",
            "Epoch 36. Train loss: 0.300847, Valid loss 0.261450, Time 00:00:00, lr 0.0001\n",
            "Epoch 37. Train loss: 0.295422, Valid loss 0.262454, Time 00:00:00, lr 0.0001\n",
            "Epoch 38. Train loss: 0.302857, Valid loss 0.253260, Time 00:00:00, lr 0.0001\n",
            "Epoch 39. Train loss: 0.297351, Valid loss 0.253987, Time 00:00:00, lr 0.0001\n",
            "Epoch 40. Train loss: 0.285815, Valid loss 0.272646, Time 00:00:00, lr 0.0001\n",
            "Epoch 41. Train loss: 0.279736, Valid loss 0.267728, Time 00:00:00, lr 0.0001\n",
            "Epoch 42. Train loss: 0.274258, Valid loss 0.253565, Time 00:00:00, lr 0.0001\n",
            "Epoch 43. Train loss: 0.279981, Valid loss 0.261569, Time 00:00:00, lr 0.0001\n",
            "Epoch 44. Train loss: 0.269533, Valid loss 0.250318, Time 00:00:00, lr 0.0001\n",
            "Epoch 45. Train loss: 0.259463, Valid loss 0.253627, Time 00:00:00, lr 0.0001\n",
            "Epoch 46. Train loss: 0.252296, Valid loss 0.261674, Time 00:00:00, lr 0.0001\n",
            "Epoch 47. Train loss: 0.253853, Valid loss 0.255792, Time 00:00:00, lr 0.0001\n",
            "Epoch 48. Train loss: 0.260406, Valid loss 0.249895, Time 00:00:00, lr 0.0001\n",
            "Epoch 49. Train loss: 0.256863, Valid loss 0.250760, Time 00:00:00, lr 0.0001\n",
            "Epoch 50. Train loss: 0.243761, Valid loss 0.272232, Time 00:00:00, lr 0.0001\n",
            "Epoch 51. Train loss: 0.248110, Valid loss 0.251872, Time 00:00:00, lr 0.0001\n",
            "Epoch 52. Train loss: 0.238562, Valid loss 0.245726, Time 00:00:00, lr 0.0001\n",
            "Epoch 53. Train loss: 0.242634, Valid loss 0.255747, Time 00:00:00, lr 0.0001\n",
            "Epoch 54. Train loss: 0.233044, Valid loss 0.252717, Time 00:00:00, lr 0.0001\n",
            "Epoch 55. Train loss: 0.232860, Valid loss 0.256722, Time 00:00:00, lr 0.0001\n",
            "Epoch 56. Train loss: 0.226236, Valid loss 0.255317, Time 00:00:00, lr 0.0001\n",
            "Epoch 57. Train loss: 0.224499, Valid loss 0.253588, Time 00:00:00, lr 0.0001\n",
            "Epoch 58. Train loss: 0.220189, Valid loss 0.255838, Time 00:00:00, lr 0.0001\n",
            "Epoch 59. Train loss: 0.218170, Valid loss 0.247429, Time 00:00:00, lr 0.0001\n",
            "Epoch 60. Train loss: 0.212516, Valid loss 0.255606, Time 00:00:00, lr 0.0001\n",
            "Epoch 61. Train loss: 0.210730, Valid loss 0.267914, Time 00:00:00, lr 0.0001\n",
            "Epoch 62. Train loss: 0.214663, Valid loss 0.266353, Time 00:00:00, lr 0.0001\n",
            "Epoch 63. Train loss: 0.201468, Valid loss 0.251031, Time 00:00:00, lr 0.0001\n",
            "Epoch 64. Train loss: 0.210004, Valid loss 0.246643, Time 00:00:00, lr 0.0001\n",
            "Epoch 65. Train loss: 0.200848, Valid loss 0.250604, Time 00:00:00, lr 0.0001\n",
            "Epoch 66. Train loss: 0.204036, Valid loss 0.267427, Time 00:00:00, lr 0.0001\n",
            "Epoch 67. Train loss: 0.203205, Valid loss 0.255710, Time 00:00:00, lr 0.0001\n",
            "Epoch 68. Train loss: 0.201299, Valid loss 0.255071, Time 00:00:00, lr 0.0001\n",
            "Epoch 69. Train loss: 0.193105, Valid loss 0.258380, Time 00:00:00, lr 0.0001\n",
            "Epoch 70. Train loss: 0.192249, Valid loss 0.264149, Time 00:00:00, lr 0.0001\n",
            "Epoch 71. Train loss: 0.186885, Valid loss 0.251878, Time 00:00:00, lr 0.0001\n",
            "Epoch 72. Train loss: 0.183903, Valid loss 0.268469, Time 00:00:00, lr 0.0001\n",
            "Epoch 73. Train loss: 0.183443, Valid loss 0.260975, Time 00:00:00, lr 0.0001\n",
            "Epoch 74. Train loss: 0.184155, Valid loss 0.267486, Time 00:00:00, lr 0.0001\n",
            "Epoch 75. Train loss: 0.182005, Valid loss 0.267740, Time 00:00:00, lr 0.0001\n",
            "Epoch 76. Train loss: 0.187648, Valid loss 0.253776, Time 00:00:00, lr 0.0001\n",
            "Epoch 77. Train loss: 0.180474, Valid loss 0.259236, Time 00:00:00, lr 0.0001\n",
            "Epoch 78. Train loss: 0.177538, Valid loss 0.257911, Time 00:00:00, lr 0.0001\n",
            "Epoch 79. Train loss: 0.178319, Valid loss 0.248238, Time 00:00:00, lr 0.0001\n",
            "Epoch 80. Train loss: 0.169235, Valid loss 0.267804, Time 00:00:00, lr 0.0001\n",
            "Epoch 81. Train loss: 0.171712, Valid loss 0.259993, Time 00:00:00, lr 0.0001\n",
            "Epoch 82. Train loss: 0.168764, Valid loss 0.254559, Time 00:00:00, lr 0.0001\n",
            "Epoch 83. Train loss: 0.165626, Valid loss 0.267766, Time 00:00:00, lr 0.0001\n",
            "Epoch 84. Train loss: 0.173423, Valid loss 0.262864, Time 00:00:00, lr 0.0001\n",
            "Epoch 85. Train loss: 0.162618, Valid loss 0.252668, Time 00:00:00, lr 0.0001\n",
            "Epoch 86. Train loss: 0.159805, Valid loss 0.261563, Time 00:00:00, lr 0.0001\n",
            "Epoch 87. Train loss: 0.163598, Valid loss 0.260901, Time 00:00:00, lr 0.0001\n",
            "Epoch 88. Train loss: 0.160276, Valid loss 0.259333, Time 00:00:00, lr 0.0001\n",
            "Epoch 89. Train loss: 0.155756, Valid loss 0.258073, Time 00:00:00, lr 0.0001\n",
            "Epoch 90. Train loss: 0.156894, Valid loss 0.255941, Time 00:00:00, lr 0.0001\n",
            "Epoch 91. Train loss: 0.158998, Valid loss 0.245919, Time 00:00:00, lr 0.0001\n",
            "Epoch 92. Train loss: 0.152334, Valid loss 0.258760, Time 00:00:00, lr 0.0001\n",
            "Epoch 93. Train loss: 0.157007, Valid loss 0.258818, Time 00:00:00, lr 0.0001\n",
            "Epoch 94. Train loss: 0.149489, Valid loss 0.264190, Time 00:00:00, lr 0.0001\n",
            "Epoch 95. Train loss: 0.147981, Valid loss 0.257545, Time 00:00:00, lr 0.0001\n",
            "Epoch 96. Train loss: 0.147403, Valid loss 0.256675, Time 00:00:00, lr 0.0001\n",
            "Epoch 97. Train loss: 0.149168, Valid loss 0.256901, Time 00:00:00, lr 0.0001\n",
            "Epoch 98. Train loss: 0.147616, Valid loss 0.250876, Time 00:00:00, lr 0.0001\n",
            "Epoch 99. Train loss: 0.145417, Valid loss 0.261981, Time 00:00:00, lr 0.0001\n",
            "Epoch 100. Train loss: 0.137977, Valid loss 0.253359, Time 00:00:00, lr 1e-05\n",
            "Epoch 101. Train loss: 0.141634, Valid loss 0.268768, Time 00:00:00, lr 1e-05\n",
            "Epoch 102. Train loss: 0.135730, Valid loss 0.253771, Time 00:00:00, lr 1e-05\n",
            "Epoch 103. Train loss: 0.135430, Valid loss 0.255815, Time 00:00:00, lr 1e-05\n",
            "Epoch 104. Train loss: 0.139833, Valid loss 0.252404, Time 00:00:00, lr 1e-05\n",
            "Epoch 105. Train loss: 0.135128, Valid loss 0.252658, Time 00:00:00, lr 1e-05\n",
            "Epoch 106. Train loss: 0.136480, Valid loss 0.255384, Time 00:00:00, lr 1e-05\n",
            "Epoch 107. Train loss: 0.128623, Valid loss 0.272919, Time 00:00:00, lr 1e-05\n",
            "Epoch 108. Train loss: 0.139619, Valid loss 0.258936, Time 00:00:00, lr 1e-05\n",
            "Epoch 109. Train loss: 0.138225, Valid loss 0.257997, Time 00:00:00, lr 1e-05\n",
            "Epoch 110. Train loss: 0.135081, Valid loss 0.265343, Time 00:00:00, lr 1e-05\n",
            "Epoch 111. Train loss: 0.137478, Valid loss 0.252996, Time 00:00:00, lr 1e-05\n",
            "Epoch 112. Train loss: 0.136209, Valid loss 0.257844, Time 00:00:00, lr 1e-05\n",
            "Epoch 113. Train loss: 0.133661, Valid loss 0.257206, Time 00:00:00, lr 1e-05\n",
            "Epoch 114. Train loss: 0.136234, Valid loss 0.260406, Time 00:00:00, lr 1e-05\n",
            "Epoch 115. Train loss: 0.137430, Valid loss 0.254591, Time 00:00:00, lr 1e-05\n",
            "Epoch 116. Train loss: 0.140094, Valid loss 0.256400, Time 00:00:00, lr 1e-05\n",
            "Epoch 117. Train loss: 0.132544, Valid loss 0.264624, Time 00:00:00, lr 1e-05\n",
            "Epoch 118. Train loss: 0.131438, Valid loss 0.265064, Time 00:00:00, lr 1e-05\n",
            "Epoch 119. Train loss: 0.130491, Valid loss 0.265463, Time 00:00:00, lr 1e-05\n",
            "Epoch 120. Train loss: 0.132114, Valid loss 0.268428, Time 00:00:00, lr 1e-05\n",
            "Epoch 121. Train loss: 0.135201, Valid loss 0.261417, Time 00:00:00, lr 1e-05\n",
            "Epoch 122. Train loss: 0.133190, Valid loss 0.253872, Time 00:00:00, lr 1e-05\n",
            "Epoch 123. Train loss: 0.129667, Valid loss 0.261899, Time 00:00:00, lr 1e-05\n",
            "Epoch 124. Train loss: 0.133498, Valid loss 0.258364, Time 00:00:00, lr 1e-05\n",
            "Epoch 125. Train loss: 0.131906, Valid loss 0.256492, Time 00:00:00, lr 1e-05\n",
            "Epoch 126. Train loss: 0.133978, Valid loss 0.255415, Time 00:00:00, lr 1e-05\n",
            "Epoch 127. Train loss: 0.131730, Valid loss 0.246798, Time 00:00:00, lr 1e-05\n",
            "Epoch 128. Train loss: 0.132761, Valid loss 0.252721, Time 00:00:00, lr 1e-05\n",
            "Epoch 129. Train loss: 0.129988, Valid loss 0.252928, Time 00:00:00, lr 1e-05\n",
            "Epoch 130. Train loss: 0.126535, Valid loss 0.250059, Time 00:00:00, lr 1e-05\n",
            "Epoch 131. Train loss: 0.129943, Valid loss 0.255240, Time 00:00:00, lr 1e-05\n",
            "Epoch 132. Train loss: 0.128547, Valid loss 0.263030, Time 00:00:00, lr 1e-05\n",
            "Epoch 133. Train loss: 0.132426, Valid loss 0.257854, Time 00:00:00, lr 1e-05\n",
            "Epoch 134. Train loss: 0.129261, Valid loss 0.257063, Time 00:00:00, lr 1e-05\n",
            "Epoch 135. Train loss: 0.132097, Valid loss 0.250428, Time 00:00:00, lr 1e-05\n",
            "Epoch 136. Train loss: 0.136215, Valid loss 0.255076, Time 00:00:00, lr 1e-05\n",
            "Epoch 137. Train loss: 0.132035, Valid loss 0.254210, Time 00:00:00, lr 1e-05\n",
            "Epoch 138. Train loss: 0.130400, Valid loss 0.257410, Time 00:00:00, lr 1e-05\n",
            "Epoch 139. Train loss: 0.126582, Valid loss 0.262102, Time 00:00:00, lr 1e-05\n",
            "Epoch 140. Train loss: 0.135795, Valid loss 0.262921, Time 00:00:00, lr 1e-05\n",
            "Epoch 141. Train loss: 0.133588, Valid loss 0.260600, Time 00:00:00, lr 1e-05\n",
            "Epoch 142. Train loss: 0.132873, Valid loss 0.262612, Time 00:00:00, lr 1e-05\n",
            "Epoch 143. Train loss: 0.136043, Valid loss 0.254072, Time 00:00:00, lr 1e-05\n",
            "Epoch 144. Train loss: 0.131731, Valid loss 0.262253, Time 00:00:00, lr 1e-05\n",
            "Epoch 145. Train loss: 0.130801, Valid loss 0.255770, Time 00:00:00, lr 1e-05\n",
            "Epoch 146. Train loss: 0.128014, Valid loss 0.262849, Time 00:00:00, lr 1e-05\n",
            "Epoch 147. Train loss: 0.124216, Valid loss 0.257807, Time 00:00:00, lr 1e-05\n",
            "Epoch 148. Train loss: 0.137077, Valid loss 0.254511, Time 00:00:00, lr 1e-05\n",
            "Epoch 149. Train loss: 0.130866, Valid loss 0.261789, Time 00:00:00, lr 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XEvS94W0JHQ_",
        "colab_type": "code",
        "outputId": "e6777748-3819-4e17-a9ad-dc3f6e4db932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from mxnet import autograd\n",
        "from mxnet import gluon\n",
        "from mxnet import image\n",
        "from mxnet import init\n",
        "from mxnet import nd\n",
        "#from mxnet.gluon.data import vision\n",
        "from mxnet.gluon.model_zoo import vision\n",
        "from mxnet.gluon import nn\n",
        "from mxnet import nd\n",
        "import pandas as pd\n",
        "import mxnet as mx\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "#from model import get_net\n",
        "\n",
        "data_dir = './'\n",
        "test_dir = 'test'\n",
        "input_dir = 'train_valid_test'\n",
        "valid_dir = 'valid'\n",
        "input_str = data_dir + '/' + input_dir + '/'\n",
        "\n",
        "netparams =\"./inception_v3.params\"\n",
        "csvname = 'p3.csv'\n",
        "ids_synsets_name = 'ids_synsets'\n",
        "\n",
        "f = open(ids_synsets_name,'rb')\n",
        "ids_synsets = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "def SaveTest(test_data,net,ctx,name,ids,synsets):\n",
        "    outputs = []\n",
        "    for data, label in tqdm(test_data):\n",
        "        output = nd.softmax(net(data.as_in_context(ctx)))\n",
        "        outputs.extend(output.asnumpy())\n",
        "    with open(name, 'w') as f:\n",
        "        f.write('id,' + ','.join(synsets) + '\\n')\n",
        "        for i, output in zip(ids, outputs):\n",
        "            f.write(i.split('.')[0] + ',' + ','.join(\n",
        "                [str(num) for num in output]) + '\\n')\n",
        "\n",
        "net = get_net(netparams,mx.gpu())\n",
        "net.hybridize()\n",
        "\n",
        "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "print(get_loss(valid_data,net,mx.gpu()))\n",
        "\n",
        "SaveTest(test_data,net,mx.gpu(),csvname,ids_synsets[0],ids_synsets[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py:420: UserWarning: load_params is deprecated. Please use load_parameters.\n",
            "  warnings.warn(\"load_params is deprecated. Please use load_parameters.\")\n",
            "  0%|          | 0/81 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2565094828605652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [04:35<00:00,  3.37s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I-RcvziyTQGC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "class  ConcatNet(nn.HybridBlock):\n",
        "    def __init__(self,net1,net2,**kwargs):\n",
        "        super(ConcatNet,self).__init__(**kwargs)\n",
        "        self.net1 = nn.HybridSequential()\n",
        "        self.net1.add(net1)\n",
        "        self.net1.add(nn.GlobalAvgPool2D())\n",
        "        self.net2 = nn.HybridSequential()\n",
        "        self.net2.add(net2)\n",
        "        self.net2.add(nn.GlobalAvgPool2D())\n",
        "    def hybrid_forward(self,F,x1,x2):\n",
        "        return F.concat(*[self.net1(x1),self.net2(x2)])\n",
        "\n",
        "class  OneNet(nn.HybridBlock):\n",
        "    def __init__(self,features,output,**kwargs):\n",
        "        super(OneNet,self).__init__(**kwargs)\n",
        "        self.features = features\n",
        "        self.output = output\n",
        "    def hybrid_forward(self,F,x1,x2):\n",
        "        return self.output(self.features(x1,x2))\n",
        "\n",
        "class Net():\n",
        "    def __init__(self,ctx,nameparams=None):\n",
        "        inception = vision.inception_v3(pretrained=True,ctx=ctx).features\n",
        "        resnet = vision.resnet152_v1(pretrained=True,ctx=ctx).features\n",
        "        self.features = ConcatNet(resnet,inception)\n",
        "        self.output = self.__get_output(ctx,nameparams)\n",
        "        self.net = OneNet(self.features,self.output)\n",
        "    def __get_output(self,ctx,ParamsName=None):\n",
        "        net = nn.HybridSequential(\"output\")\n",
        "        with net.name_scope():\n",
        "            net.add(nn.Dense(256,activation='relu'))\n",
        "            net.add(nn.Dropout(.5))\n",
        "            net.add(nn.Dense(120))\n",
        "        if ParamsName is not None:\n",
        "            net.collect_params().load(ParamsName,ctx)\n",
        "        else:\n",
        "            net.initialize(init = init.Xavier(),ctx=ctx)\n",
        "        return net\n"
      ]
    },
    {
      "metadata": {
        "id": "zfJaGgIqVqhJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}